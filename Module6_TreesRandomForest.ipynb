{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shstreuber/Data-Mining/blob/master/Module6_TreesRandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAbTzFEkU3X8"
      },
      "source": [
        "# **Module 6: CLASSIFICATION with Random Forest**\n",
        "In this module, we are going to study different ways of setting up advanced classification models. At the end of this notebook, you will be able to:\n",
        "* Explain what classification trees do and how, taken together as Random Forest, they produce more reliable results than single trees\n",
        "* Build a Random Forest algorithm\n",
        "\n",
        "**Be sure to expand all the hidden cells, run all the code, and do all the exercises--you will need the techniques for the lesson lab!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**AGAIN: What is the Classification Process?**\n",
        "When you work with algorithms, you basically follow a pretty standard process. This process consists of the following steps:\n",
        "0. **Preparation and Setup**: Loading the data and verifying that the data has indeed loaded\n",
        "1. **Exploratory Data Analysis**: Getting a basic understanding of the data, including number of columns and rows, data types, data shape and distribution (remember 5-number summary?), and the like\n",
        "2. **Preprocessing**: Cleaning the data up and reducing them to the smallest useful dataset with which you and your hardware will be able to work. This includes building a reduced dataframe.\n",
        "3. **Splitting your data into Training and Test set**: We use the Training set to configure the model and the Test set to evaluate how well the model works. NOTE that you will need to remove the class attribute from the test set because this is the attribute whose values you want to predict.\n",
        "4. **Building and Training the model**: Here, you select the algorithm you are going to use and you configure it using the Training set.\n",
        "5. **Evaluating the Quality of the model**: This is where you apply the configured model to the Test set and determine how accurately it handles the test data. In other words, we compare the calculated class values to the actual class values shown in the test set. At the end, you'll use THREE methods to evaluate:\n",
        "* The accuracy score (shows how the calculated predictions for the test data class compare to the actual class values that you have split off)\n",
        "* The Confusion Matrix (visualization which compares the number of predictions with the number of true class values)\n",
        "* The Classification Report (numeric breakdown and overview of accuracy and more)\n",
        "\n",
        "And that's it! Let's dive into the material now!\n"
      ],
      "metadata": {
        "id": "nB2SQtHhi4BZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj-zwToQQfKv"
      },
      "source": [
        "#**1. Tree-Based Classification**\n",
        "A Classification tree assigns data records to discrete levels (or labels) in a class attribute. It is built through binary recursive partitioning, which means that data is being split into partitions, then sub-partitions, and sub-sub-partitions, and so on. The outcome is a tree with a root, several branches, and leaves like the one below (which comes from [this awesome post](https://towardsdatascience.com/https-medium-com-lorrli-classification-and-regression-analysis-with-decision-trees-c43cdbc58054) on classification trees that will tell you almost everything you need to know):\n",
        "\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/classtree.jpeg\" width=\"400\">\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD7yiF_hb39f"
      },
      "source": [
        "Now take a look at the first video in which I explain this in more detail (and with examples):\n",
        "\n",
        "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/BxQAIyDxDKg\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "Nx_Do6Cqcb-i",
        "outputId": "18b6c099-26d5-4787-c1b9-be72968976d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7e323ff03e80>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"560\"\n",
              "            height=\"315\"\n",
              "            src=\"https://www.youtube.com/embed/BxQAIyDxDKg\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from IPython.display import IFrame  # This is just for me so I can embed videos\n",
        "IFrame(src=\"https://www.youtube.com/embed/BxQAIyDxDKg\", width=560, height=315)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While decision tree models are awesome, they have some real disadvantages:\n",
        "1. If you build your training and test sets with random sampling, no two decision trees about the same dataset will be the same. So, can you ever really tell what the *real* result of your math is? Not really\n",
        "2. They don't really work well with really big datasets because they classify *everything* in a dataset, to the point of going into too much detail. [This is called overfitting](https://aws.amazon.com/what-is/overfitting/) and can waste considerable resources.  \n",
        "\n",
        "Wouldn't it be much better to combine different trees from randomly sampled subsets of the same dataset and then check where these trees come to the same solution?\n",
        "\n",
        "##**Welcome to Random Forest!**\n",
        "\n",
        "Random Forest doesn't build just one tree--it builds an entire classroom full of trees, each one of which is based on a slightly different training set (which is, in fact, a small randomized subset of the big overall training set). To save processing power, Random Forest then picks just a random few of the attributes to consider when building each tree, so that no two trees are based on the same attributes. Finally, Random Forest evaluates all the trees it has constructed and, for a given prediction, outputs the class assignment that is the mode of the classes (classification) or, if you run it as a regression tree, the mean prediction (regression) of the individual trees.\n",
        "\n",
        "<div>\n",
        "<img src=\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/images/randomforest2.png\" width=\"600\">\n",
        "</div>\n",
        "\n",
        "So, we have:\n",
        "* A number of trees\n",
        "* Using a random subset of features in the dataset to make their split decisions\n",
        "* Built on a number of slightly different training subsets, selected as random samples with replacement (= bootstrap aggregating or bagging) from the overall training set\n",
        "* A voting function that selects the mode of the classes (classification or the mean prediction (regression)\n",
        "\n",
        "In other words, we introduce dual randomness into our classification in order to pick the best model from the places where all the individual trees overlap. That leaves us with much greater accuracy for our model.\n",
        "\n",
        "**Got Questions?**\n",
        "\n",
        "Take a look at the awesome video below."
      ],
      "metadata": {
        "id": "ER6QHwFfdLH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IFrame(src=\"https://www.youtube.com/embed/v6VJ2RO66Ag\", width=560, height=315)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "sR1bjUqls-VB",
        "outputId": "0b038bc8-6f90-4e5d-c536-f34e7dd77920"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7e323fd51e10>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"560\"\n",
              "            height=\"315\"\n",
              "            src=\"https://www.youtube.com/embed/v6VJ2RO66Ag\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dQO2OAj4P3N"
      },
      "source": [
        "##**1.0. Preparation and Setup**\n",
        "There really isn't anything new going on between the modules on k Nearest Neighbor and Naive Bayes and this one. As with our previous problems, we will use the insurance dataset again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKqieySsTlEi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import spatial\n",
        "import statsmodels.api as sm\n",
        "\n",
        "from IPython.display import HTML # This is just for me so I can embed videos\n",
        "from IPython.display import Image # This is just for me so I can embed images\n",
        "\n",
        "#Reading in the data as insurance dataframe\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/shstreuber/Data-Mining/master/data/insurance_with_categories.csv\")\n",
        "\n",
        "#Verifying that we can see the data\n",
        "insurance.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WIw-g2X17xr"
      },
      "source": [
        "Now we are ready for our Exploratory Data Analysis (EDA)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_5mxtgN0z1V"
      },
      "source": [
        "##**1.1 Exploratory Data Analysis (EDA)**\n",
        "This is always the first step. Even though we already know this dataset, let's walk through the motions again. In the previous module, we used the ydata profiling package to generate a beautiful HTML interface with tabs that showed us everything we needed to know and then some more--but it required installing a new package. You may not always have the user permissions to do this. So, below is the basic process of data investigation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6biFr9F-3ElZ"
      },
      "source": [
        "###**1.1.1 Data Shape and Distribution**\n",
        "Run each code line below to see what it does."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Mhdmb_f3MEX"
      },
      "outputs": [],
      "source": [
        "insurance.describe(include = 'all'), print(\"***DATA OVERVIEW***\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "insurance.dtypes, print(\"***DATA TYPES***\")"
      ],
      "metadata": {
        "id": "aqxP2wLho04a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "st5DIA7pAk5b"
      },
      "outputs": [],
      "source": [
        "insurance.corr(numeric_only=1), print(\"***DATA CORRELATIONS***\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpRT_lu-A7oO"
      },
      "source": [
        "## Your Turn\n",
        "What do these commands show you? Why is this important? Explain in the text field below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ms5D7ikkCQdA"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzsJMd2c8VzN"
      },
      "source": [
        "###**1.1.2 Some Basic Visualiations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hc5RRKrV6XHH"
      },
      "outputs": [],
      "source": [
        "# Data Distribution (numeric data only)\n",
        "insurance.hist()\n",
        "insurance.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cLAXDbdCy1h"
      },
      "source": [
        "I know ... I promised you a pie plot in Module 1, and that was too hard back then. Here are two ways to do this.\n",
        "\n",
        "**NOTE** that all plots require numeric information, so you have to first count the size of each level in a categorical attribute and then build the pie size based on that. You already know groupby, so all you need to do is get the size of each group with the size() command--or you can make an array from the attribute and count the values. Both ways are shown below.\n",
        "\n",
        "**Uncomment each of the code lines below separately to see how they work**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oxif4cJsGwrw"
      },
      "outputs": [],
      "source": [
        "# You can also use the groupby command we have learned earlier in this course.\n",
        "# insurance.groupby('sex').size().plot(kind='pie', autopct='%.2f')\n",
        "# insurance['sex'].value_counts().plot(kind='pie', autopct='%.2f')\n",
        "# insurance.groupby('children').size().plot(kind='pie', autopct='%.2f')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiO1ZGogF-qz"
      },
      "source": [
        "##Your Turn\n",
        "Now analyze the second code line above and then display just the counts for the levels in the 'region' attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQrh01KwGLPy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFDdFQr400ml"
      },
      "source": [
        "##**1.2. Preprocessing: Building the Dataframe for Analysis**\n",
        "We will, as before, use the \"region\" attribute as the class attribute and the numeric attributes (age, bmi, children, charges) in the insurance dataframe as the predictors. Since we already know that no data is missing, all we have to do is assemble the insurance2 dataframe we are going to use.\n",
        "\n",
        "In the code row below, build the insurance2 dataframe we need (if you don't remember how to do this, review last week's module in which we built this dataframe already):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co5zZ6tv1TEs"
      },
      "outputs": [],
      "source": [
        "insurance2 = pd.DataFrame(insurance, columns = ['age', 'bmi', 'children','charges','region'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdBOZ8EFL31k"
      },
      "source": [
        "##**1.3. Setting up the Training and the Test Sets**\n",
        "Just like before, we need to build the training set and the test set again. We want a **80% training/ 20% test split**. Finish the code below to build this (if you can't remember how to do this, use the code from any of the two previous workbooks):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqnZw_LrL2eZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x=insurance2.iloc[:,:4] # all parameters\n",
        "y=insurance2['region'] # class labels 'southwest', 'southeast', 'northwest', 'northeast'\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=.20)\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"X_test shape: {}\".format(X_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPq3h9nMZeWj"
      },
      "source": [
        "##**1.4. Build and Train the Random Forest classifier**\n",
        "We are going to use the [RandomForestClassifier from sklearn.ensemble](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html). The RandomForestClassifier has a number of really interesting parameters that we can control in order to optimize our model to run quickly and efficiently, especially the sub-sample size, which is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DrXRCY0Kpfb"
      },
      "source": [
        "###**1.4.1 Building the Classifier**\n",
        "\n",
        "The most important parameters are:\n",
        "* **n_estimators int, default=100** --\n",
        "The number of trees in the forest.\n",
        "* **criterion{“gini”, “entropy”}, default=”gini”** --\n",
        "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain. Note: this parameter is tree-specific.\n",
        "* **max_features{“auto”, “sqrt”, “log2”}, int or float, default=”auto”** --\n",
        "The number of features to consider when looking for the best split: If int, then consider max_features features at each split. If “auto”, then max_features=sqrt(n_features). If “log2”, then max_features=log2(n_features).\n",
        "If None, then max_features=n_features.\n",
        "* **max_depthint, default=None** --\n",
        "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
        "* **min_samples_split int or float, default=2**\n",
        "The minimum number of samples required to split an internal node\n",
        "* **bootstrap bool, default=True** -- Whether bootstrap samples are used when building trees (which is 50% of the whole idea behind Random Forest). If False, the whole dataset is used to build each tree.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf_3YnrvabQ6"
      },
      "outputs": [],
      "source": [
        "# Importing the Random Forest library.\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(42)\n",
        "\n",
        "# Configuring the classifier and using get_params to double-check all the parameters with which it is configured\n",
        "rf = RandomForestClassifier()\n",
        "rf.get_params(deep=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9Bz5lp9bkUm"
      },
      "source": [
        "###**1.4.2 Training the Classifier**\n",
        "rf is our Random Forest classifier. As before, we use .fit to train the classifier on the dataset.\n",
        "X_train[['age', 'bmi', 'children', 'charges']] are all the feature columns of the training set, and y_train is 'region'. Based on these we want to make a prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbCEF6dBbpTI"
      },
      "outputs": [],
      "source": [
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43eGwtTNQGuQ"
      },
      "source": [
        "## **1.5. Use the Classifier to test and predict**\n",
        "There is nothing different about the steps below than what you have already done. Uncomment the second line starting with \"print\" if you would like to see the output of your predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etLxnittWVnw"
      },
      "outputs": [],
      "source": [
        "y_pred = rf.predict(X_test)\n",
        "# print(y_pred) # If you want to see the big long list, uncomment this line!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiN9SqhmvqqZ"
      },
      "source": [
        "##**1.6. Evaluate the Quality of the Model**\n",
        "OK, now we can calculate the accuracy score and then look at the Confusion Matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp9p8I9Mw5Xj"
      },
      "source": [
        "###**1.6.1 Accuracy Score**\n",
        "\n",
        "First, the accuracy score:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJfmd6xhwE_k"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu6Xr18NyOMo"
      },
      "source": [
        "Would you accept a result of 38% on an exam? (Take a look at the grading scale for this course to see where that would land you). Let's see what the Confusion Matrix tells us about this lousy score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP2tHRaOiKdO"
      },
      "source": [
        "###**1.6.2 Confusion Matrix**\n",
        "And now the Confusion Matrix:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkFxx6fzhoki"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred, labels=rf.classes_)\n",
        "cm_display = ConfusionMatrixDisplay(cm, display_labels=rf.classes_).plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xCQYkOTyoQT"
      },
      "source": [
        "Let's look at the \"northwest\" row: Out of 21+24+8+13 = 66 true northwest values, only 24 were predicted correctly. 21 were predicted as northeast, 8 as southeast, and 13 as southwest.\n",
        "\n",
        "##Your Turn\n",
        "What about the \"southwest\" row? Are the results better or worse? Write your explanation into the text field below:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VimEARFQznBx"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCwtXVeikzSe"
      },
      "source": [
        "###**1.6.3 Classification Report**\n",
        "The Classification Report gives us even more insights into how well (or, in our case, badly) our model performs. To read it correctly, we first have to define a few terms:\n",
        "\n",
        "* **precision** (also called positive predictive value) is the number of correctly identified positive results divided by the number of all positive results, including those not identified correctly ((true positives) / (true positives + false positives)). Said another way, “for all instances classified positive, what percent was correct?”\n",
        "* **recall** (also known as sensitivity) is the number of correctly identified positive results divided by the number of all samples that should have been identified as positive ((true positives) / (true positives + false negatives)). Said another way, “for all instances that were actually positive, what percent was classified correctly?\n",
        "* **f-1 score** is the harmonic mean of the precision and recall. The highest possible value of F1 is 1, indicating perfect precision and recall, and the lowest possible value is 0, if either the precision or the recall is zero. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n",
        "* **support** is the number of actual occurrences of the class in the specified dataset.\n",
        "\n",
        "Now you have all the tools to read the classification report below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WtL372SimXm"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred, labels=['northeast', 'northwest', 'southeast','southwest']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0jsX4ft0GtM"
      },
      "source": [
        "Can you explain what these numbers mean for the insurance2 dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "27m6QMK9y03O"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yzm2qZq42gK7"
      },
      "source": [
        "# If you get Stuck"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Data Shape\n",
        "The analysis shows the connections and the dependencies between the different attributes. This is important because we want the X attributes (or features) to be independent from each other; the only dependent attribute should be the class attribute. If the X attributes are too correlated, we are looking at [multicollinearity](https://www.statisticshowto.com/multicollinearity/), which can impact the usefulness of our model."
      ],
      "metadata": {
        "id": "X91_8i_hn2wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2 Basic Visualizations\n",
        "insurance.groupby('region').count()"
      ],
      "metadata": {
        "id": "B_4e0QC6ngxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwVb732S1061"
      },
      "outputs": [],
      "source": [
        "# This is the solution for task 2 above.\n",
        "insurance2 = pd.DataFrame(insurance, columns = ['age', 'bmi', 'children','charges','region'])\n",
        "insurance2.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uN7kB8IM1NXF"
      },
      "outputs": [],
      "source": [
        "# This is the solution for task 3 above:\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.6.2 The prediction is just as bad."
      ],
      "metadata": {
        "id": "ZM5o8lS8wAt7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}